<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Introduction</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>



<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>Introduction</h2>

<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement  a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. </p>

<p>In this project, data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants will be used. These participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. </p>

<p>The goal of the project is to predict the manner in which they did the exercise. </p>

<p>I&#39;d like to kindly thank the people at <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a> for allowing us to make use of their data.</p>

<h2>Synopsis</h2>

<p>The data-set provided for training the model contained several issues. The most important one was the number of columns to use for the model. Since my expectation was that the relationship to many of these would be very tight, but at the same time would decrease the performance of the machine learning phase, I decided to drop most of the seemingly related columns and keep just the rest.</p>

<p>With this in mind, several prediction models have been tested, of which some are included in this report. Confusion matrices have been printed to validate the accuracy and out of sample errors. As it turns out the Random Forest Model delivered a 99% accuracy using either the independent randomForest package, or using the integration with caret: </p>

<ul>
<li>Random Forest - randomForest package: execution time several seconds, accuracy 99%</li>
<li>Random Forest - caret package: execution time close to 15 minutes, accuracy 99%</li>
<li>Decision tree - caret package: several seconds, accuracy very low</li>
<li>Boosted trees - caret package: approximately 5 minutes, accuracy 93%</li>
</ul>

<p>As it turns out the above randomForest model has resulted in a 100% score for the submission part of this Data Science module.</p>

<h2>Preparation</h2>

<p>Here we load some required libraries:</p>

<pre><code class="r"># install.packages(&quot;caret&quot;, dependencies=TRUE, quiet = TRUE)
library(caret)
</code></pre>

<pre><code class="r">library(ggplot2)
</code></pre>

<pre><code class="r">library(randomForest)
</code></pre>

<pre><code class="r">library(rpart)
</code></pre>

<h2>Getting Data</h2>

<p>In this section we download the data, load the downloaded files into memory.</p>

<pre><code class="r">trainingFile &lt;- download.file(&#39;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&#39;, &#39;pml-training.csv&#39;, method=&quot;curl&quot;)

trainSet &lt;- read.csv(&quot;pml-training.csv&quot;)

testingFile &lt;- download.file(&#39;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&#39;, &#39;pml-testing.csv&#39;, method=&quot;curl&quot;)

testSet &lt;- read.csv(&quot;pml-testing.csv&quot;)
</code></pre>

<h2>Exploratory Data Analysis</h2>

<p>Here&#39;s an excerpt of the two data-sets, trainSet and headSet:</p>

<pre><code class="r">head(trainSet[grep(&quot;^yaw|^roll|^pitch|^picth|^classe&quot;, names(trainSet))],2);
</code></pre>

<pre><code>##   roll_belt pitch_belt yaw_belt roll_arm pitch_arm yaw_arm roll_dumbbell
## 1      1.41       8.07    -94.4     -128      22.5    -161         13.05
## 2      1.41       8.07    -94.4     -128      22.5    -161         13.13
##   pitch_dumbbell yaw_dumbbell roll_forearm pitch_forearm yaw_forearm
## 1         -70.49       -84.87         28.4         -63.9        -153
## 2         -70.64       -84.71         28.3         -63.9        -153
##   classe
## 1      A
## 2      A
</code></pre>

<pre><code class="r">head(trainSet[grep(&quot;^yaw|^roll|^pitch|^picth|^classe&quot;, names(testSet))],2);
</code></pre>

<pre><code>##   roll_belt pitch_belt yaw_belt roll_arm pitch_arm yaw_arm roll_dumbbell
## 1      1.41       8.07    -94.4     -128      22.5    -161         13.05
## 2      1.41       8.07    -94.4     -128      22.5    -161         13.13
##   pitch_dumbbell yaw_dumbbell roll_forearm pitch_forearm yaw_forearm
## 1         -70.49       -84.87         28.4         -63.9        -153
## 2         -70.64       -84.71         28.3         -63.9        -153
</code></pre>

<pre><code class="r">summary(trainSet$classe)
</code></pre>

<pre><code>##    A    B    C    D    E 
## 5580 3797 3422 3216 3607
</code></pre>

<pre><code class="r">nrow(trainSet)
</code></pre>

<pre><code>## [1] 19622
</code></pre>

<pre><code class="r">nrow(testSet)
</code></pre>

<pre><code>## [1] 20
</code></pre>

<p>Some brief feature plots to analyse a part of the data are as follows. There are clear relationships visible between the different sensors, as well as spurious patterns.</p>

<pre><code class="r">featurePlot(x=trainSet[,grep(&quot;^yaw&quot;, names(trainSet))], trainSet$classe, plot=&quot;pairs&quot;)
</code></pre>

<p><img src="figure/unnamed-chunk-9.png" alt="plot of chunk unnamed-chunk-9"/> </p>

<pre><code class="r">featurePlot(x=trainSet[,grep(&quot;^roll&quot;, names(trainSet))], trainSet$classe, plot=&quot;pairs&quot;)
</code></pre>

<p><img src="figure/unnamed-chunk-10.png" alt="plot of chunk unnamed-chunk-10"/> </p>

<pre><code class="r">featurePlot(x=trainSet[,grep(&quot;^pitch|^picth&quot;, names(trainSet))], trainSet$classe, plot=&quot;pairs&quot;)
</code></pre>

<p><img src="figure/unnamed-chunk-11.png" alt="plot of chunk unnamed-chunk-11"/> </p>

<p>The following can be noted about the data through the file and documentation:</p>

<ul>
<li>The classe variable in the data-set is describing the way the exercise was performed. There are five different values, each describing one way the exercise was performed, whereby class A is the correct way, the others are describing commonly made mistakes.</li>
<li>There are a lot of similar column names in the file, and they might be highly correlated, and not all needed. It might be useful to apply Principle Component Analysis.</li>
<li>The data contains a lot of columns, many of them having near zero or NA values. We might want to remove, ignore or impute them.</li>
<li>Note the wondrous misspelling of &ldquo;pitch&rdquo; versus &ldquo;picth&rdquo; in the column names.</li>
<li>We need to convert the factor variable &ldquo;classe&rdquo;, and make sure other columns are numeric.</li>
<li>The classe variable is not present in the test-set. This makes sense, it&#39;s what we have to predict.</li>
</ul>

<h2>Cleaning Data</h2>

<p>Before we engage in the Machine Learning phase we need to clean up the data. This will be according to some of the above comments made in the Exploratory Data Analysis section. </p>

<p>An important note is that I decided to be very rough in the cleansing, and will just keep the yaw, roll, pitch columns for the various sensors, and drop the rest. The classe column will also be included. </p>

<pre><code class="r"># Filter out just the yaw, roll, pi[ct]h and classe columns, drop the rest
cleanedTrainSet &lt;- trainSet[grep(&quot;^yaw|^roll|^pitch|^picth|^classe&quot;, names(trainSet))]

# Convert the classe column to a factor.
cleanedTrainSet$classe &lt;- as.factor(cleanedTrainSet$classe)

# Number of rows in the cleaned training set
nrow(cleanedTrainSet)
</code></pre>

<pre><code>## [1] 19622
</code></pre>

<pre><code class="r"># Validating if there are no empty rows / columns in the resulting set:
sum(complete.cases(cleanedTrainSet))
</code></pre>

<pre><code>## [1] 19622
</code></pre>

<h2>Machine Learning Using Random Forest</h2>

<p>In this first machine learning exercise, we will be using randomForest modeling. The accuracy of this model is supposed to be high. As it turns out, the speed turned out to be fairly okay, just a couple of seconds to generate against the training-set. However, if I run the randomForest generation as a parameter to caret&#39;s train package, it takes an awfully long time.</p>

<pre><code class="r">inTrain &lt;- createDataPartition(y=cleanedTrainSet$classe, p=0.8, list=FALSE)

training &lt;- cleanedTrainSet[inTrain,]
testing &lt;- cleanedTrainSet[-inTrain,]

# Create a random forest model
randomForestModel &lt;- randomForest(classe ~ . , data=training)

# Cross-validate the predictions against the test-set
predictions &lt;- predict(randomForestModel, newdata=testing)
</code></pre>

<p>And last, let&#39;s plot a confusionMatrix to show how well we did:</p>

<pre><code class="r">confusionMatrix(predictions, testing$classe)
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1115    4    0    1    0
##          B    1  742    3    0    0
##          C    0   12  675    2    3
##          D    0    1    5  640    2
##          E    0    0    1    0  716
## 
## Overall Statistics
##                                         
##                Accuracy : 0.991         
##                  95% CI : (0.988, 0.994)
##     No Information Rate : 0.284         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.989         
##  Mcnemar&#39;s Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             0.999    0.978    0.987    0.995    0.993
## Specificity             0.998    0.999    0.995    0.998    1.000
## Pos Pred Value          0.996    0.995    0.975    0.988    0.999
## Neg Pred Value          1.000    0.995    0.997    0.999    0.998
## Prevalence              0.284    0.193    0.174    0.164    0.184
## Detection Rate          0.284    0.189    0.172    0.163    0.183
## Detection Prevalence    0.285    0.190    0.176    0.165    0.183
## Balanced Accuracy       0.999    0.988    0.991    0.996    0.996
</code></pre>

<p>The confusion matrix shows a very high accuracy of close to 99%, which is very good! Sensitivity (missed positives) show that incorrectly categorization of the test class is very low. Specificity is showing the same; the likelihood of incorrect categorization of <em>not</em> being the test class is very low (negatives called positives). So I think we found a good model. </p>

<h2>Machine Learning Using a Decision Tree</h2>

<p>As a fun exercise, another attempt at learning the model can be done using a tree model. The below shows how this is done using caret.</p>

<pre><code class="r">inTrain &lt;- createDataPartition(y=cleanedTrainSet$classe, p=0.8, list=FALSE)

training &lt;- cleanedTrainSet[inTrain,]
testing &lt;- cleanedTrainSet[-inTrain,]

# Create a tree model
treeModel &lt;- train(classe ~ . , data=training, method=&quot;rpart&quot;)

# Cross-validate the predictions against the test-set
predictions &lt;- predict(treeModel, newdata=testing)
</code></pre>

<pre><code class="r">confusionMatrix(predictions, testing$classe)
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1018  375  318  380  151
##          B    2  130   14    4    4
##          C   93  254  352  259  258
##          D    0    0    0    0    0
##          E    3    0    0    0  308
## 
## Overall Statistics
##                                         
##                Accuracy : 0.461         
##                  95% CI : (0.445, 0.477)
##     No Information Rate : 0.284         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.292         
##  Mcnemar&#39;s Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             0.912   0.1713   0.5146    0.000   0.4272
## Specificity             0.564   0.9924   0.7333    1.000   0.9991
## Pos Pred Value          0.454   0.8442   0.2895      NaN   0.9904
## Neg Pred Value          0.942   0.8331   0.8774    0.836   0.8857
## Prevalence              0.284   0.1935   0.1744    0.164   0.1838
## Detection Rate          0.259   0.0331   0.0897    0.000   0.0785
## Detection Prevalence    0.572   0.0393   0.3100    0.000   0.0793
## Balanced Accuracy       0.738   0.5818   0.6239    0.500   0.7131
</code></pre>

<p>The confusionMatrix shows a very low accuracy. The model training has been untuned, and can probably perform much better.</p>

<h2>Machine Learning Using a Boosted Tree</h2>

<p>A further attempt at learning the model can be done using a boosted tree. The below shows how this is done. The execution time turned out to very long. </p>

<pre><code class="r">inTrain &lt;- createDataPartition(y=cleanedTrainSet$classe, p=0.8, list=FALSE)

training &lt;- cleanedTrainSet[inTrain,]
testing &lt;- cleanedTrainSet[-inTrain,]

# Create a boosted tree model
gbmModel &lt;- train(classe ~ . , data=training, method=&quot;gbm&quot;, verbose = FALSE)

# Cross-validate the predictions against the test-set
predictions &lt;- predict(gbmModel, newdata=testing)
</code></pre>

<pre><code class="r">confusionMatrix(predictions, testing$classe)
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1056   27    0    1    4
##          B   33  684   24    8   12
##          C    7   36  635   17    7
##          D   10   10   20  613   14
##          E   10    2    5    4  684
## 
## Overall Statistics
##                                         
##                Accuracy : 0.936         
##                  95% CI : (0.928, 0.943)
##     No Information Rate : 0.284         
##     P-Value [Acc &gt; NIR] : &lt; 2e-16       
##                                         
##                   Kappa : 0.919         
##  Mcnemar&#39;s Test P-Value : 0.00023       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             0.946    0.901    0.928    0.953    0.949
## Specificity             0.989    0.976    0.979    0.984    0.993
## Pos Pred Value          0.971    0.899    0.905    0.919    0.970
## Neg Pred Value          0.979    0.976    0.985    0.991    0.989
## Prevalence              0.284    0.193    0.174    0.164    0.184
## Detection Rate          0.269    0.174    0.162    0.156    0.174
## Detection Prevalence    0.277    0.194    0.179    0.170    0.180
## Balanced Accuracy       0.967    0.938    0.954    0.968    0.971
</code></pre>

<p>Results appear to be quite good, around 93%. The sensitivity and specificity is not that great though.</p>

<h2>Test results, and Write result files</h2>

<p>As it turns out the Random Forest model as my first guess has proven to deliver very good results. Thus, in the below section we use the downloaded testSet file that does not contain the classe variable for our final predictions. Using this model we will predict the type of exercise that was used, and use that in the submission assignment.</p>

<pre><code class="r"># Now test out the results against the testSet loaded from the website.
predictionsTestSet &lt;- predict(randomForestModel, newdata = testSet)
</code></pre>

<p>The below section writes the result files for the submission part of the assignment. Please use getwd() to locate the folder where these files are written.</p>

<pre><code class="r">pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0(&quot;problem_id_&quot;,i,&quot;.txt&quot;)
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictionsTestSet)
</code></pre>

</body>

</html>
